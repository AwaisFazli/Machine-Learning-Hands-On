{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3cdd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC, LinearSVR, SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c165504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d62e94ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(iris.target[:10] == 2).astype(\"float64\") \n",
    "#only getting the IrisVerginica and converting it into BinaryClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a875ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris[\"data\"][:,(2,3)] # only retrieving the last 2 columns\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49860615",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = Pipeline([\n",
    "    (\"scaler\" , StandardScaler()),\n",
    "    (\"linear_svc\" , LinearSVC(C = 1, loss= \"hinge\")), #C determines the width of road (boundary walls)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8501af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb109a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a3bd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = Pipeline([\n",
    "    (\"scaler\" , StandardScaler()),\n",
    "    (\"linear_svc\" , SVC(kernel = \"linear\",C = 1)), #C determines the width of road (boundary walls)\n",
    "])\n",
    "\n",
    "svc.fit(X,y)\n",
    "svc.predict([[5.5,1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4ecf0",
   "metadata": {},
   "source": [
    "The LinearSVC class regularizes the bias term, so you should center the training set first by subtracting its mean. This is automatic if you scale the data using the StandardScaler . Moreover, make sure you set the loss hyperparameter to \"hinge\" , as it is not the default value. Finally, for better performance you should set the dual hyperparameter to False , unless there are more features than training instances.\n",
    "\n",
    "The hinge loss is a loss function used for training classifiers, most notably the SVM. ... A negative distance from the boundary incurs a high hinge loss. This essentially means that we are on the wrong side of the boundary, and that the instance will be classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4101f55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7f2c676d90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a915171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Polnomial Features', PolynomialFeatures(degree=3)),\n",
       "                ('Standard Scaler', StandardScaler()),\n",
       "                ('Linear Classifier', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_svm_clf = Pipeline([\n",
    "    (\"Polnomial Features\", PolynomialFeatures(degree = 3)),\n",
    "    (\"Standard Scaler\", StandardScaler()),\n",
    "    (\"Linear Classifier\", LinearSVC(C = 1, loss=\"hinge\"))\n",
    "])\n",
    "\n",
    "poly_svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2daad076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd12d15",
   "metadata": {},
   "source": [
    "Adding polynomial features is simple to implement and can work great with all sorts\n",
    "of Machine Learning algorithms (not just SVMs), but at a low polynomial degree it\n",
    "cannot deal with very complex datasets, and with a high polynomial degree it creates\n",
    "a huge number of features, making the model too slow.\n",
    "\n",
    "Fortunately, when using SVMs you can apply an almost miraculous mathematical\n",
    "technique called the kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6701179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('StandardScaler', StandardScaler()),\n",
       "                ('svm_classifier', SVC(C=1, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_kernel = Pipeline([\n",
    "    (\"StandardScaler\", StandardScaler()),\n",
    "    (\"svm_classifier\", SVC(kernel = \"poly\", degree = 3, coef0 = 1, C = 1))\n",
    "])\n",
    "#The hyperparameter coef0 controls how much the model is influenced by \n",
    "#high-degree polynomials versus low-degree polynomials.\n",
    "\n",
    "poly_kernel.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ba8aaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_kernel.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ce4037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standard Scaler', StandardScaler()),\n",
       "                ('Svm_ clf', SVC(C=0.001, gamma=5))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel = Pipeline([\n",
    "    (\"standard Scaler\", StandardScaler()),\n",
    "    (\"Svm_ clf\", SVC(kernel = \"rbf\", gamma = 5, C= 0.001))\n",
    "])\n",
    "\n",
    "rbf_kernel.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe306d0",
   "metadata": {},
   "source": [
    "Just like the polynomial features method, the similarity features method can be useful with any Machine Learning algorithm, but it may be computationally expensive to compute all the additional features, especially on large training sets. However, once again the kernel trick does its SVM magic: it makes it possible to obtain a similar\n",
    "result as if you had added many similarity features, without actually having to add them. Let’s try the Gaussian RBF kernel using the SVC class\n",
    "\n",
    "Increasing gamma makes the bell-shape curve narrower and as a result each instance’s range of influence is smaller: the decision boundary ends up being more irregular, wiggling around individual instances. Conversely, a small gamma value makes the bell-shaped curve wider, so instances have a larger range of influence, and the decision boundary ends up smoother. So Gamma acts like a regularization hyperparameter: if your model is overfitting, you should reduce it, and if it is underfitting, you should increase it (similar to the C hyperparameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29e3aacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(epsilon=1.5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svr = LinearSVR(epsilon = 1.5)\n",
    "linear_svr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ee872",
   "metadata": {},
   "source": [
    "The SVM algorithm is quite versatile: not only does it support linear and nonlinear classification, but it also supports linear and nonlinear regression.\n",
    "The trick is to reverse the objective: instead of trying to fit the largest possible street between two classes while limiting margin violations, SVM Regression tries to fit as many instances as possible on the street while limiting margin violations (i.e., instances off the street). The width of the street is controlled by a hyperparameter ε (epsilon) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1d76f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_poly = SVR(kernel = \"poly\", degree = 2, C= 100, epsilon = 0.1)\n",
    "svr_poly.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72abb806",
   "metadata": {},
   "source": [
    "Using Scikit-Learn’s SVR class (which supports the kernel trick). The SVR class is the regression equivalent of the SVC class, and the LinearSVR class is the regression equivalent of the LinearSVC class. The LinearSVR class scales linearly with the size of the training set (just like the LinearSVC class), while the SVR class gets much too slow when the training set grows large (just like the SVC class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713af9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
